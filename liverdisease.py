# -*- coding: utf-8 -*-
"""LiverDisease.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AGMlE8i9S1H5hnoAQ-QJ4rmQhuGwLiPk
"""

import numpy as np
import pandas as pd
import plotly.express as px

import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

import tensorflow as tf

data=pd.read_csv('/content/indian_liver_patient.csv')

data

data.info() #we can see here there is only one generic column object

#numerical attribute and outliers
data.describe()

"""PreProcessing"""

#preprocessing
data.isna().sum()#it calculate no of null values in each attribute

data['Albumin_and_Globulin_Ratio' ].mean()
data['Albumin_and_Globulin_Ratio'] = data['Albumin_and_Globulin_Ratio'].fillna(data['Albumin_and_Globulin_Ratio'].mean())
data.isna().sum()

#count plot shows the ratio of liver patient
sns.countplot(x ='Dataset', data=data )
plt.show()

#count plot shows the ratio of gender of liver patients
sns.countplot(x ='Gender', data=data )
plt.show()

##Removing duplicate values
data=data[-data.duplicated(subset=None,keep='first')]

#Generating Heat Map to show correlation
data_set=data.loc[:,data.columns!="Gender"]
ax = sns.heatmap(data_set.corr(),linewidths=0.5 ,annot=True)

plt.title( "Liver Disease Heat Map" )
plt.show()

"""Encoding"""

def binary_encode(df, column, positive_value):
    df = df.copy()
    df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)
    return df

data = binary_encode(data, 'Gender', 'Male')

"""Let's change the labels to 0, 1 instead of 1, 2"""

data = binary_encode(data, 'Dataset', 1)
data

"""Splitting And Scaling"""

y = data['Dataset']
X = data.drop('Dataset', axis=1)

scaler = StandardScaler()

X = scaler.fit_transform(X)
X

"""Over Sampling"""

y=data['Dataset']
X=data.drop(['Dataset'],axis=1)
disease=data[data['Dataset']==1]
no_disease=data[data['Dataset']==0]

print(disease.shape,no_disease.shape)

from imblearn.over_sampling import RandomOverSampler

os=RandomOverSampler(random_state=10)

X_res, y_res = os.fit_resample(X, y)

X_res.shape,y_res.shape

"""Algorithms"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=101)

"""KNN"""

import time

# record start time
start = time.time()
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X_train,y_train)
pred = knn.predict(X_test)
print("The time of execution of above program is :", time.time()-start)
from sklearn import metrics
metrics.plot_roc_curve(knn, X_test, y_test)
plt.show()

knn = KNeighborsClassifier(n_neighbors=1)

KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',metric_params=None, n_jobs=1, n_neighbors=1, p=2,weights='uniform')

from sklearn.metrics import classification_report,confusion_matrix
print(confusion_matrix(y_test,pred))

print(classification_report(y_test,pred))

error_rate = []

for i in range(1,40):
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train,y_train)
    pred_i = knn.predict(X_test)
    error_rate.append(np.mean(pred_i != y_test))

plt.figure(figsize=(10,6))
plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',markerfacecolor='red', markersize=10)
plt.title('Error Rate vs. K Value')
plt.xlabel('K')
plt.ylabel('Error Rate')

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

cm = confusion_matrix(y_test, pred)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])

cm_display.plot()
plt.show()

print('Confusion matrix\n\n', cm)
from sklearn.metrics import classification_report

print(classification_report(y_test, pred))

"""Random Forest"""

import time
start = time.time()
from sklearn import metrics
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(random_state=0)
rfc.fit(X_train, y_train)
y_pred = rfc.predict(X_test)
end = time.time()

print("The time of execution of above program is :", time.time()-start)
metrics.plot_roc_curve(rfc, X_test, y_test)
plt.show()

print('WITH K=1')
print('\n')
print(confusion_matrix(y_test,y_pred))
print('\n')
print(classification_report(y_test,pred))

from sklearn.metrics import accuracy_score
print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

cm = confusion_matrix(y_test, y_pred)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])

cm_display.plot()
plt.show()

print('Confusion matrix\n\n', cm)
from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

"""Ada Boost"""

import time
start = time.time()
from sklearn.ensemble import AdaBoostClassifier
clf = AdaBoostClassifier(n_estimators=100, random_state=0)
clf.fit(X_train, y_train)
y_Pred = clf.predict(X_test)
end = time.time()
print("The time of execution of above program is :", time.time()-start)
metrics.plot_roc_curve(clf, X_test, y_test)
plt.show()

y_Pred = clf.predict(X_test)

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

cm = confusion_matrix(y_test, y_Pred)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])

cm_display.plot()
plt.show()

print('Confusion matrix\n\n', cm)
from sklearn.metrics import classification_report

print(classification_report(y_test, y_Pred))

"""Linear SVM"""

import time
start = time.time()
from sklearn.svm import SVC
classifier = SVC(kernel = 'linear', random_state = 0)
classifier.fit(X_train, y_train)
y_Pred = classifier.predict(X_test)
end = time.time()
print("The time of execution of above program is :", time.time()-start)

metrics.plot_roc_curve(classifier, X_test, y_test)
plt.show()

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

cm = confusion_matrix(y_test, y_Pred)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])

cm_display.plot()
plt.show()

print('Confusion matrix\n\n', cm)
from sklearn.metrics import classification_report

print(classification_report(y_test, y_Pred))

"""Naive Bayes"""

import time
start = time.time()
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)

# training the model on training set
from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(X_train, y_train)

# making predictions on the testing set
y_pred = gnb.predict(X_test)
end = time.time()
print("The time of execution of above program is :", time.time()-start)


metrics.plot_roc_curve(gnb, X_test, y_test)
plt.show()

# comparing actual response values (y_test) with predicted response values (y_pred)
from sklearn import metrics
print("Gaussian Naive Bayes model accuracy(in %):", metrics.accuracy_score(y_test, y_pred)*100)
from sklearn.metrics import confusion_matrix, accuracy_score

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

cm = confusion_matrix(y_test, y_pred)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])

cm_display.plot()
plt.show()

print('Confusion matrix\n\n', cm)
from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

"""Decision Tree (Ginni Index)"""

import time
start = time.time()
from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)
end = time.time()
print("The time of execution of above program is :", time.time()-start)
metrics.plot_roc_curve(clf, X_test, y_test)
plt.show()

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

from sklearn import tree
tree.plot_tree(clf)

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

cm = confusion_matrix(y_test, y_pred)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])

cm_display.plot()
plt.show()

print('Confusion matrix\n\n', cm)
from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

"""Gradient Boosting Classifier"""

from sklearn.datasets import make_hastie_10_2
from sklearn.ensemble import GradientBoostingClassifier

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)
import time
start = time.time()

clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,
...     max_depth=1, random_state=0).fit(X_train, y_train)
clf.fit(X_test, y_test)
end = time.time()
print("The time of execution of above program is :", time.time()-start)

metrics.plot_roc_curve(clf, X_test, y_test)
plt.show()

print("Accuracy score (training): {0:.3f}".format(clf.score(X_train, y_train)))
print("Accuracy score (validation): {0:.3f}".format(clf.score(X_test, y_test)))

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy
from sklearn import metrics
predictions = clf.predict(X_test)
cm = confusion_matrix(y_test,predictions)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])

cm_display.plot()
plt.show()

print('Confusion matrix\n\n', cm)
from sklearn.metrics import classification_report

print(classification_report(y_test,predictions))

"""XGBoost Classifier"""

from xgboost import XGBClassifier

import time
start = time.time()
xgb_clf = XGBClassifier()
xgb_clf.fit(X_train, y_train)
score = xgb_clf.score(X_test, y_test)
print(score)
metrics.plot_roc_curve(xgb_clf, X_test, y_test)
plt.show()
y_pred=xgb_clf.predict(X_test)
end = time.time()
print("The time of execution of above program is :", time.time()-start)

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

cm = confusion_matrix(y_test, y_pred)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])

cm_display.plot()
plt.show()

print('Confusion matrix\n\n', cm)
from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

"""Extra Tree Method in Python"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.datasets import load_iris
from sklearn.metrics import confusion_matrix

import time
start = time.time()
clf = ExtraTreesClassifier(n_estimators=100)
print(clf)
from sklearn.metrics import confusion_matrix
clf.fit(X_train, y_train)
score = clf.score(X_train, y_train)
print("Score: ", score)
metrics.plot_roc_curve(clf, X_test, y_test)
plt.show()
end = time.time()
print("The time of execution of above program is :", time.time()-start)

cv_scores = cross_val_score(clf,X_train, y_train , cv=5 )
print("CV average score: %.2f" % cv_scores.mean())

ypred = clf.predict(X_test)

cm = confusion_matrix(y_test, ypred)
print(cm)

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

cm = confusion_matrix(y_test, ypred)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])

cm_display.plot()
plt.show()

print('Confusion matrix\n\n', cm)
from sklearn.metrics import classification_report

print(classification_report(y_test, ypred))

"""Logistic Regression"""

import time
start = time.time()
from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(random_state=0).fit(X_train, y_train)
clf = LogisticRegression()
print(clf)
from sklearn.metrics import confusion_matrix
clf.fit(X_train, y_train)
score = clf.score(X_train, y_train)
print("Score: ", score)
metrics.plot_roc_curve(clf, X_test, y_test)
plt.show()
ypred = clf.predict(X_test)
end = time.time()
print("The time of execution of above program is :", time.time()-start)

cv_scores = cross_val_score(clf,X_train, y_train , cv=5 )
print("CV average score: %.2f" % cv_scores.mean())

cm = confusion_matrix(y_test, ypred)
print(cm)

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

cm = confusion_matrix(y_test, ypred)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])

cm_display.plot()
plt.show()

print('Confusion matrix\n\n', cm)
from sklearn.metrics import classification_report

print(classification_report(y_test, ypred))